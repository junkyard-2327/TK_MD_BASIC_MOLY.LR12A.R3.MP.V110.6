#ifndef __C2K_FOE_CMIF_H__
#define __C2K_FOE_CMIF_H__

#include "reg_access.h"
#include "c2k_base_addr_cmif.h"

#define CMIF_C2K_FOE_REG_BASE                                         (CMIF_C2K_RAKE_FOE_OFFSET)
#define CMIF_FOE_CTL_1XRTT                                            (CMIF_C2K_FOE_REG_BASE + 0x0000)
#define CMIF_FOE_PARAM_1XRTT                                          (CMIF_C2K_FOE_REG_BASE + 0x0004)
#define CMIF_FOE_FINE_1XRTT                                           (CMIF_C2K_FOE_REG_BASE + 0x0008)
#define CMIF_FOE_SQPWR_1XRTT                                          (CMIF_C2K_FOE_REG_BASE + 0x000C)
#define CMIF_FOE_CTL_EVDO                                             (CMIF_C2K_FOE_REG_BASE + 0x0010)
#define CMIF_FOE_FINE_I_EVDO                                          (CMIF_C2K_FOE_REG_BASE + 0x0014)
#define CMIF_FOE_FINE_Q_EVDO                                          (CMIF_C2K_FOE_REG_BASE + 0x0018)
#define CMIF_FOE_COARSE_I_EVDO                                        (CMIF_C2K_FOE_REG_BASE + 0x001C)
#define CMIF_FOE_COARSE_Q_EVDO                                        (CMIF_C2K_FOE_REG_BASE + 0x0020)
#define CMIF_FOE_SNR_ACC_EVDO                                         (CMIF_C2K_FOE_REG_BASE + 0x0024)
#define CMIF_FOE_SNR_TOT_EVDO                                         (CMIF_C2K_FOE_REG_BASE + 0x0028)
#define CMIF_FOE_SNR_FNG_EVDO(i)                                      (CMIF_C2K_FOE_REG_BASE + 0x002C + ((i) * 0x4))

#define M_CMIF_FOE_CTL_1XRTT_RD()                                     REG_READ(CMIF_FOE_CTL_1XRTT)
#define M_CMIF_FOE_PARAM_1XRTT_RD()                                   REG_READ(CMIF_FOE_PARAM_1XRTT)
#define M_CMIF_FOE_FINE_1XRTT_RD()                                    REG_READ(CMIF_FOE_FINE_1XRTT)
#define M_CMIF_FOE_SQPWR_1XRTT_RD()                                   REG_READ(CMIF_FOE_SQPWR_1XRTT)
#define M_CMIF_FOE_CTL_EVDO_RD()                                      REG_READ(CMIF_FOE_CTL_EVDO)
#define M_CMIF_FOE_FINE_I_EVDO_RD()                                   REG_READ(CMIF_FOE_FINE_I_EVDO)
#define M_CMIF_FOE_FINE_Q_EVDO_RD()                                   REG_READ(CMIF_FOE_FINE_Q_EVDO)
#define M_CMIF_FOE_COARSE_I_EVDO_RD()                                 REG_READ(CMIF_FOE_COARSE_I_EVDO)
#define M_CMIF_FOE_COARSE_Q_EVDO_RD()                                 REG_READ(CMIF_FOE_COARSE_Q_EVDO)
#define M_CMIF_FOE_SNR_ACC_EVDO_RD()                                  REG_READ(CMIF_FOE_SNR_ACC_EVDO)
#define M_CMIF_FOE_SNR_TOT_EVDO_RD()                                  REG_READ(CMIF_FOE_SNR_TOT_EVDO)
#define M_CMIF_FOE_SNR_FNG_EVDO_RD(i)                                 REG_READ(CMIF_FOE_SNR_FNG_EVDO(i))

#define M_CMIF_FOE_CTL_1XRTT_WR(reg)                                  REG_WRITE(CMIF_FOE_CTL_1XRTT, reg)
#define M_CMIF_FOE_PARAM_1XRTT_WR(reg)                                REG_WRITE(CMIF_FOE_PARAM_1XRTT, reg)
#define M_CMIF_FOE_FINE_1XRTT_WR(reg)                                 REG_WRITE(CMIF_FOE_FINE_1XRTT, reg)
#define M_CMIF_FOE_SQPWR_1XRTT_WR(reg)                                REG_WRITE(CMIF_FOE_SQPWR_1XRTT, reg)
#define M_CMIF_FOE_CTL_EVDO_WR(reg)                                   REG_WRITE(CMIF_FOE_CTL_EVDO, reg)
#define M_CMIF_FOE_FINE_I_EVDO_WR(reg)                                REG_WRITE(CMIF_FOE_FINE_I_EVDO, reg)
#define M_CMIF_FOE_FINE_Q_EVDO_WR(reg)                                REG_WRITE(CMIF_FOE_FINE_Q_EVDO, reg)
#define M_CMIF_FOE_COARSE_I_EVDO_WR(reg)                              REG_WRITE(CMIF_FOE_COARSE_I_EVDO, reg)
#define M_CMIF_FOE_COARSE_Q_EVDO_WR(reg)                              REG_WRITE(CMIF_FOE_COARSE_Q_EVDO, reg)
#define M_CMIF_FOE_SNR_ACC_EVDO_WR(reg)                               REG_WRITE(CMIF_FOE_SNR_ACC_EVDO, reg)
#define M_CMIF_FOE_SNR_TOT_EVDO_WR(reg)                               REG_WRITE(CMIF_FOE_SNR_TOT_EVDO, reg)
#define M_CMIF_FOE_SNR_FNG_EVDO_WR(i, reg)                            REG_WRITE(CMIF_FOE_SNR_FNG_EVDO(i), reg)

#define CMIF_FOE_CTL_1XRTT_RST_BIT_LSB                                (0)
#define CMIF_FOE_CTL_1XRTT_RST_BIT_WIDTH                              (8)
#define CMIF_FOE_CTL_1XRTT_RST_BIT_MASK                               ((UINT32) (((1<<CMIF_FOE_CTL_1XRTT_RST_BIT_WIDTH)-1) << CMIF_FOE_CTL_1XRTT_RST_BIT_LSB) )
#define CMIF_FOE_CTL_1XRTT_RST_FLD_WR(reg, val)                       (reg |= (val) << CMIF_FOE_CTL_1XRTT_RST_BIT_LSB)
#define CMIF_FOE_CTL_1XRTT_RST_FLD_RD()                               ((M_CMIF_FOE_CTL_1XRTT_RD() & CMIF_FOE_CTL_1XRTT_RST_BIT_MASK) >> CMIF_FOE_CTL_1XRTT_RST_BIT_LSB)

#define CMIF_FOE_PARAM_1XRTT_RDY_BIT_LSB                              (8)
#define CMIF_FOE_PARAM_1XRTT_RDY_BIT_WIDTH                            (1)
#define CMIF_FOE_PARAM_1XRTT_RDY_BIT_MASK                             ((UINT32) (((1<<CMIF_FOE_PARAM_1XRTT_RDY_BIT_WIDTH)-1) << CMIF_FOE_PARAM_1XRTT_RDY_BIT_LSB) )
#define CMIF_FOE_PARAM_1XRTT_RDY_FLD_WR(reg, val)                     (reg |= (val) << CMIF_FOE_PARAM_1XRTT_RDY_BIT_LSB)
#define CMIF_FOE_PARAM_1XRTT_RDY_FLD_RD()                             ((M_CMIF_FOE_PARAM_1XRTT_RD() & CMIF_FOE_PARAM_1XRTT_RDY_BIT_MASK) >> CMIF_FOE_PARAM_1XRTT_RDY_BIT_LSB)

#define CMIF_FOE_PARAM_1XRTT_NR_BIT_LSB                               (0)
#define CMIF_FOE_PARAM_1XRTT_NR_BIT_WIDTH                             (8)
#define CMIF_FOE_PARAM_1XRTT_NR_BIT_MASK                              ((UINT32) (((1<<CMIF_FOE_PARAM_1XRTT_NR_BIT_WIDTH)-1) << CMIF_FOE_PARAM_1XRTT_NR_BIT_LSB) )
#define CMIF_FOE_PARAM_1XRTT_NR_FLD_WR(reg, val)                      (reg |= (val) << CMIF_FOE_PARAM_1XRTT_NR_BIT_LSB)
#define CMIF_FOE_PARAM_1XRTT_NR_FLD_RD()                              ((M_CMIF_FOE_PARAM_1XRTT_RD() & CMIF_FOE_PARAM_1XRTT_NR_BIT_MASK) >> CMIF_FOE_PARAM_1XRTT_NR_BIT_LSB)

#define CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_LSB                            (0)
#define CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_WIDTH                          (32)
#define CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_MASK                           ((UINT32) (((1<<CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_WIDTH)-1) << CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_LSB) )
#define CMIF_FOE_FINE_1XRTT_FOE_HZ_FLD_WR(reg, val)                   (reg |= (val) << CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_LSB)
#define CMIF_FOE_FINE_1XRTT_FOE_HZ_FLD_RD()                           ((M_CMIF_FOE_FINE_1XRTT_RD() & CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_MASK) >> CMIF_FOE_FINE_1XRTT_FOE_HZ_BIT_LSB)

#define CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_LSB                           (0)
#define CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_WIDTH                         (32)
#define CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_MASK                          ((UINT32) (((1<<CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_WIDTH)-1) << CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_LSB) )
#define CMIF_FOE_SQPWR_1XRTT_PWR_TH_FLD_WR(reg, val)                  (reg |= (val) << CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_LSB)
#define CMIF_FOE_SQPWR_1XRTT_PWR_TH_FLD_RD()                          ((M_CMIF_FOE_SQPWR_1XRTT_RD() & CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_MASK) >> CMIF_FOE_SQPWR_1XRTT_PWR_TH_BIT_LSB)

#define CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_LSB                       (8)
#define CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_WIDTH                     (1)
#define CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_MASK                      ((UINT32) (((1<<CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_WIDTH)-1) << CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_LSB) )
#define CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_FLD_WR(reg, val)              (reg |= (val) << CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_LSB)
#define CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_FLD_RD()                      ((M_CMIF_FOE_CTL_EVDO_RD() & CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_MASK) >> CMIF_FOE_CTL_EVDO_AFC_EVDO_MODE_BIT_LSB)

#define CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_LSB                            (2)
#define CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_WIDTH                          (1)
#define CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_MASK                           ((UINT32) (((1<<CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_WIDTH)-1) << CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_LSB) )
#define CMIF_FOE_CTL_EVDO_AFC_BUSY_FLD_WR(reg, val)                   (reg |= (val) << CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_LSB)
#define CMIF_FOE_CTL_EVDO_AFC_BUSY_FLD_RD()                           ((M_CMIF_FOE_CTL_EVDO_RD() & CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_MASK) >> CMIF_FOE_CTL_EVDO_AFC_BUSY_BIT_LSB)

#define CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_LSB                            (1)
#define CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_WIDTH                          (1)
#define CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_MASK                           ((UINT32) (((1<<CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_WIDTH)-1) << CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_LSB) )
#define CMIF_FOE_CTL_EVDO_AFC_LOCK_FLD_WR(reg, val)                   (reg |= (val) << CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_LSB)
#define CMIF_FOE_CTL_EVDO_AFC_LOCK_FLD_RD()                           ((M_CMIF_FOE_CTL_EVDO_RD() & CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_MASK) >> CMIF_FOE_CTL_EVDO_AFC_LOCK_BIT_LSB)

#define CMIF_FOE_CTL_EVDO_AFC_RST_BIT_LSB                             (0)
#define CMIF_FOE_CTL_EVDO_AFC_RST_BIT_WIDTH                           (1)
#define CMIF_FOE_CTL_EVDO_AFC_RST_BIT_MASK                            ((UINT32) (((1<<CMIF_FOE_CTL_EVDO_AFC_RST_BIT_WIDTH)-1) << CMIF_FOE_CTL_EVDO_AFC_RST_BIT_LSB) )
#define CMIF_FOE_CTL_EVDO_AFC_RST_FLD_WR(reg, val)                    (reg |= (val) << CMIF_FOE_CTL_EVDO_AFC_RST_BIT_LSB)
#define CMIF_FOE_CTL_EVDO_AFC_RST_FLD_RD()                            ((M_CMIF_FOE_CTL_EVDO_RD() & CMIF_FOE_CTL_EVDO_AFC_RST_BIT_MASK) >> CMIF_FOE_CTL_EVDO_AFC_RST_BIT_LSB)

#define CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_LSB                       (0)
#define CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_WIDTH                     (32)
#define CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_MASK                      ((UINT32) (((1<<CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_WIDTH)-1) << CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_LSB) )
#define CMIF_FOE_FINE_I_EVDO_EST_FINE_I_FLD_WR(reg, val)              (reg |= (val) << CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_LSB)
#define CMIF_FOE_FINE_I_EVDO_EST_FINE_I_FLD_RD()                      ((M_CMIF_FOE_FINE_I_EVDO_RD() & CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_MASK) >> CMIF_FOE_FINE_I_EVDO_EST_FINE_I_BIT_LSB)

#define CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_LSB                       (0)
#define CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_WIDTH                     (32)
#define CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_MASK                      ((UINT32) (((1<<CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_WIDTH)-1) << CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_LSB) )
#define CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_FLD_WR(reg, val)              (reg |= (val) << CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_LSB)
#define CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_FLD_RD()                      ((M_CMIF_FOE_FINE_Q_EVDO_RD() & CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_MASK) >> CMIF_FOE_FINE_Q_EVDO_EST_FINE_Q_BIT_LSB)

#define CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_LSB                   (0)
#define CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_WIDTH                 (32)
#define CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_MASK                  ((UINT32) (((1<<CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_WIDTH)-1) << CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_LSB) )
#define CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_FLD_WR(reg, val)          (reg |= (val) << CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_LSB)
#define CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_FLD_RD()                  ((M_CMIF_FOE_COARSE_I_EVDO_RD() & CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_MASK) >> CMIF_FOE_COARSE_I_EVDO_EST_COARSE_I_BIT_LSB)

#define CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_LSB                   (0)
#define CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_WIDTH                 (32)
#define CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_MASK                  ((UINT32) (((1<<CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_WIDTH)-1) << CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_LSB) )
#define CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_FLD_WR(reg, val)          (reg |= (val) << CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_LSB)
#define CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_FLD_RD()                  ((M_CMIF_FOE_COARSE_Q_EVDO_RD() & CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_MASK) >> CMIF_FOE_COARSE_Q_EVDO_EST_COARSE_Q_BIT_LSB)

#define CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_LSB             (8)
#define CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_WIDTH           (24)
#define CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_MASK            ((UINT32) (((1<<CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_WIDTH)-1) << CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_LSB) )
#define CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_FLD_WR(reg, val)    (reg |= (val) << CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_LSB)
#define CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_FLD_RD()            ((M_CMIF_FOE_SNR_ACC_EVDO_RD() & CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_MASK) >> CMIF_FOE_SNR_ACC_EVDO_ACC_NSLOTS_SNR_EVDO_BIT_LSB)

#define CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_LSB                             (0)
#define CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_WIDTH                           (8)
#define CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_MASK                            ((UINT32) (((1<<CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_WIDTH)-1) << CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_LSB) )
#define CMIF_FOE_SNR_ACC_EVDO_CNT_FLD_WR(reg, val)                    (reg |= (val) << CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_LSB)
#define CMIF_FOE_SNR_ACC_EVDO_CNT_FLD_RD()                            ((M_CMIF_FOE_SNR_ACC_EVDO_RD() & CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_MASK) >> CMIF_FOE_SNR_ACC_EVDO_CNT_BIT_LSB)

#define CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_LSB                     (0)
#define CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_WIDTH                   (16)
#define CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_MASK                    ((UINT32) (((1<<CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_WIDTH)-1) << CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_LSB) )
#define CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_FLD_WR(reg, val)            (reg |= (val) << CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_LSB)
#define CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_FLD_RD()                    ((M_CMIF_FOE_SNR_TOT_EVDO_RD() & CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_MASK) >> CMIF_FOE_SNR_TOT_EVDO_ACC_EST_SNR_BIT_LSB)

#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_LSB                   (16)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_WIDTH                 (16)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_MASK                  ((UINT32) (((1<<CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_WIDTH)-1) << CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_LSB) )
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_FLD_WR(reg, val)          (reg |= (val) << CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_LSB)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_FLD_RD(i)                 ((M_CMIF_FOE_SNR_FNG_EVDO_RD(i) & CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_MASK) >> CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX1_BIT_LSB)

#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_LSB                   (0)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_WIDTH                 (16)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_MASK                  ((UINT32) (((1<<CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_WIDTH)-1) << CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_LSB) )
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_FLD_WR(reg, val)          (reg |= (val) << CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_LSB)
#define CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_FLD_RD(i)                 ((M_CMIF_FOE_SNR_FNG_EVDO_RD(i) & CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_MASK) >> CMIF_FOE_SNR_FNG_EVDO_SNR_FNG_N_RX0_BIT_LSB)

#endif /* __C2K_FOE_CMIF_H__ */
